---
title: "Data Acquisition with APIs in R"
format:
  html: default
editor_options: 
  chunk_output_type: console
---
  
You can download this .qmd file from [here](https://github.com/proback/264_fall_2025/blob/main/12_apis.qmd).  Just hit the Download Raw File button.

Credit to Brianna Heggeseth and Leslie Myint from Macalester College for a few of these descriptions and examples.

```{r}
#| include: FALSE

library(tidyverse)
library(stringr)
library(httr2)
library(httr)
library(tidycensus)
```


# Introduction to APIs

When we interact with sites like The New York Times, Zillow, and Google, we are accessing their data via a graphical layout (e.g., images, colors, columns) that is easy for humans to read but hard for computers.

An **API** stands for **Application Programming Interface**, and this term describes a general class of tool that allows computers, rather than humans, to interact with an organization's data. How does this work?

- When we use web browsers to navigate the web, our browsers communicate with web servers using a technology called [HTTP](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol) or Hypertext Transfer Protocol to get information that is formatted into the display of a web page.
- Programming languages such as R can also use HTTP to communicate with web servers. The easiest way to do this is via [Web APIs](https://en.wikipedia.org/wiki/Web_API), or Web Application Programming Interfaces, which focus on transmitting raw data, rather than images, colors, or other appearance-related information that humans interact with when viewing a web page.

A large variety of web APIs provide data accessible to programs written in R (and almost any other programming language!). Almost all reasonably large commercial websites offer APIs. Several developers have tried to maintain lists of public APIs, with various levels of success in maintenance and accuracy; you might check out [here](https://public-api-lists.github.io/public-api-lists/) or [here](https://github.com/toddmotto/public-apis) or [here](https://github.com/public-apis/public-apis) or [here](https://free-apis.github.io/#/).

For our purposes of obtaining data, APIs exist where website developers make data nicely packaged for consumption.  The language HTTP (hypertext transfer protocol) underlies APIs, and the R package `httr()` (and now the updated `httr2()`) was written to map closely to HTTP with R. Essentially you send a request to the website (server) where you want data from, and they send a response, which should contain the data (plus other stuff).

Many APIs (and their wrapper packages) require users to obtain a **key** to use their services.

- This lets organizations keep track of what data is being used.
- It also **rate limits** their API and ensures programs don't make too many requests per day/minute/hour. Be aware that most APIs do have rate limits --- especially for their free tiers.

The case studies in this document provide a really quick introduction to data acquisition, just to get you started and show you what's possible.  For more information, this link (among others) can be somewhat helpful:

- https://nceas.github.io/oss-lessons/data-liberation/intro-webscraping.html


# Accessing web APIs directly

## Movie data from OMDB

Here's an example of getting data from a website that attempts to make imdb movie data available as an API.

Initial instructions:

- go to omdbapi.com under the API Key tab and request a free API key
- store your key as discussed below
- explore the examples at omdbapi.com


### Handling API keys

You'll want to keep your API key handy for when you want to make requests for data from omdbapi.com, but you'll also want to keep in secret so that others can't use steal your key.  

**One approach** is to copy and paste your key into a new text file:

- File > New File > Text File
- Save as `omdb_api_key.txt` in the same folder as this `.qmd`.

You could then read in the key with code like this:

```{r}
#| eval: FALSE

omdb_api_key <- readLines("~/SDS264_F25/omdb_api_key.txt")
```

While this works, the problem is once we start backing up our files to GitHub, your API key will also appear on GitHub, and your API key will no longer be secret.  To get around this, you can list `omdb_api_key.txt` in a `.gitignore` file, since GitHub does not back up files and folders listed in `.gitignore`.

Here are two ways to create the .gitignore file:

1. Manually:

- Open a text editor (e.g. File > New File > Text File)
- Save the empty file as .gitignore in the root directory of your R project. Ensure the file name starts with a dot.

2. Using RStudio:

- Go to the Git pane in RStudio
- Right-click on a file you want to ignore and select "Ignore". RStudio will automatically create or update the .gitignore file with an entry for that file.

Your .gitignore file can contain file names, folder names, extensions (e.g. *.pdf to ignore all pdf files), etc.  For example, in our class folder (264_fall_2025), I have a subfolder called DS2_preview_work where I store all the materials I'm working on but which aren't quite ready to publish.

A **second approach** is to use *environment variables*:

Environment variables, or envvars for short, are a cross platform way of passing information to processes.  For passing envvars to R, you can list name-value pairs in a file called .Renviron in your home directory. The easiest way to edit it is to run:

```{r}
#| eval: FALSE

usethis::edit_r_environ("project")  # opens an .Renviron window

# Add a line like: OMDB_KEY='myspecialkey'
# Save the .Renviron file
# Close down RStudio
# Restart RStudio

Sys.getenv()   # to see if your new key is listed

omdb_api_key <- Sys.getenv("OMDB_KEY")
print(omdb_api_key)  # see if it works
```


### Data from Coco (2017)

We will first obtain data about the movie Coco from 2017.

```{r}
omdb_api_key <- readLines("~/264_fall_2025/DS2_preview_work/omdb_api_key.txt")

# Alternatively, load your OMDB API key using:
# omdb_api_key <- Sys.getenv("OMDB_KEY")

# Find url exploring examples at omdbapi.com
url <- str_c("http://www.omdbapi.com/?t=Coco&y=2017&apikey=", omdb_api_key)

coco <- GET(url)   # coco holds response from server
coco               # Status of 200 is good!

details <- content(coco, "parse")   
details                         # get a list of 25 pieces of information
details$Year                    # how to access details
details[[2]]                    # since a list, another way to access
```


### On Your Own - OMDB

1. Build a data set for a collection of movies by completing the **FILL IN** sections in the code below:

```{r}
#| eval: FALSE

# Create a vector of 5 movie names you want to study
#  - must figure out pattern in URL for obtaining different movies
movies <- c("Shrek the Third", "Ratatouille", "Harry Potter and the Order of the Phoenix", "Alvin and the Chipmunks", "Ocean's Thirteen")

# Set up empty tibble
omdb <- tibble(Title = character(), Rated = character(), Genre = character(),
       Actors = character(), Metascore = double(), imdbRating = double(),
       BoxOffice = double())

# Use for loop to run through API request process 5 times,
#   each time filling the next row in the tibble
#  - can do max of 1000 GETs per day
for(i in 1:5) {
  url <- str_c("http://www.omdbapi.com/?t=",str_replace_all(movies[[i]]," ","+"),"&y=2007&apikey=",omdb_api_key)
  Sys.sleep(0.5)
  onemovie <- GET(url)
  details <- content(onemovie, "parse")
  omdb[i,1] <- details$Title
  omdb[i,2] <- details$Rated  # rating
  omdb[i,3] <- details$Genre  # genres (single string - could be more than one)
  omdb[i,4] <- details$Actors  # actors (single string - could be more than one)
  omdb[i,5] <- parse_number(details$Metascore)  # metascore (be sure it is numeric)
  omdb[i,6] <- parse_number(details$imdbRating)  # imdb rating (be sure it is numeric)
  omdb[i,7] <- parse_number(details$BoxOffice)  # box office (be sure it is numeric)
}

omdb

#  could use stringr functions to further organize this data - separate 
#    different genres, different actors, etc.  But don't need to now.
```


## National Park data

A SDS 264 final project by Mary Wu and Jenna Graff started with a small data set on 56 national parks from [kaggle](https://www.kaggle.com/datasets/nationalparkservice/park-biodiversity), and supplemented with columns for the park address (a single column including address, city, state, and zip code) and a list of available activities (a single character column with activities separated by commas) that they acquired using APIs from the park websites themselves.

Initial instructions:

- Request API [here](https://www.nps.gov/subjects/developer/get-started.htm)
- Check out [API guide](https://www.nps.gov/subjects/developer/guides.htm)

```{r}
# Load in your API key
nps_api_key <- readLines("~/264_fall_2025/DS2_preview_work/nps_api_key.txt")

nps_api_key <- readLines("~/SDS264_F25/national_park_api_key.txt")

# Alternatively, load your NPS API key using:
# nps_api_key <- Sys.getenv("NPS_KEY")

# Read in park codes from Kaggle
np_kaggle <- read_csv("~/264_fall_2025/Data/parks.csv")
park_code <- np_kaggle$`Park Code` 
```

Notice how far we have to drill down to find addresses and activities!

```{r}
# Try grabbing elements for one park
url1 <- str_c("https://developer.nps.gov/api/v1/parks?parkCode="
                , park_code[1], "&api_key=", nps_api_key)
one_park <- GET(url1)
details <- content(one_park, "parse")  
# check out what's available
#str(details)   
#details$data[[1]]

parks_address <- str_c(
  details$data[[1]]$addresses[[1]]$line1, " ",
  details$data[[1]]$addresses[[1]]$line3, " ",
  details$data[[1]]$addresses[[1]]$line2, " ",
  details$data[[1]]$addresses[[1]]$city, " ",
  details$data[[1]]$addresses[[1]]$stateCode, ", " ,
  details$data[[1]]$addresses[[1]]$postalCode
)

park_activities <- details$data[[1]]$activities[[1]]$name
for (j in 2:length(details$data[[1]]$activities)) {
  park_activities <- str_c(park_activities, ", ",
                         details$data[[1]]$activities[[j]]$name)
}
```

Once we figure out how to get the desired elements for one park, we can use a for loop with changing park_code to get those elements for all 56 parks:

```{r}  
# Now get addresses for all 56 parks
parks_address <- vector("character", length = length(park_code))
for (i in 1:56) {
  url1 <- str_c("https://developer.nps.gov/api/v1/parks?parkCode=", 
                park_code[i], "&api_key=", nps_api_key)
  one_park <- GET(url1)
  details <- content(one_park, "parse")
  parks_address[i] <- str_c(
    details$data[[1]]$addresses[[1]]$line1, " ",
    details$data[[1]]$addresses[[1]]$line3, " ",
    details$data[[1]]$addresses[[1]]$line2, " ",
    details$data[[1]]$addresses[[1]]$city, " ",
    details$data[[1]]$addresses[[1]]$stateCode, ", " ,
    details$data[[1]]$addresses[[1]]$postalCode
  )
}

# Repeat for the list of activities
activity_list <- vector("character", length = length(park_code))
for(i in 1:56) { 
  url1 <- str_c("https://developer.nps.gov/api/v1/parks?parkCode=",
                park_code[i], "&api_key=", nps_api_key)
  one_park <- GET(url1)
  details <- content(one_park, "parse")
  activity_list[i] <- details$data[[1]]$activities[[1]]$name
  for (j in 2:length(details$data[[1]]$activities)) {
    activity_list[i] <- str_c(activity_list[i], ", ",
                              details$data[[1]]$activities[[j]]$name)
  }
}

park_data <- tibble(park_code, parks_address, activity_list)
park_data
```


## US Census Bureau data 

The US Census Bureau produces a ton of publicly-available data that's useful for creating maps and analyzing demographic trends.  As with OMDB and NPS, you can request an API key to request data.  But, since so many researchers find census  data useful, R developers have created **wrapper packages** to make common requests easier to navigate with customized R functions.  In this section, we will compare the direct API approach to a wrapper package approach to acquiring census data.

Initial instructions:

Navigate to <https://api.census.gov/data/key_signup.html> to obtain a Census API key:

- Organization: St. Olaf College
- Email: Your St. Olaf email address

You will get the message:

> Your request for a new API key has been successfully submitted. Please check your email. In a few minutes you should receive a message with instructions on how to activate your new key.

Check your email. Be sure to save your key using a file specified in .gitignore or a variable defined in .Renviron.


### Navigating API documentation using httr

Navigate to the [Census API user guide](https://www.census.gov/data/developers/guidance/api-user-guide.html) and click on the "Example API Queries" tab.

Let's look at the Population Estimates Example and the American Community Survey (ACS) Example. These examples walk us through the steps to incrementally build up a URL to obtain desired data. This URL is known as a web API **request**. 

https://api.census.gov/data/2019/acs/acs1?get=NAME,B02015_009E,B02015_009M&for=state:*

- `https://api.census.gov`: This is the **base URL**.
    - `http://`: The **scheme**, which tells your browser or program how to communicate with the web server. This will typically be either `http:` or `https:`.
    - `api.census.gov`: The **hostname**, which is a name that identifies the web server that will process the request.
- `data/2019/acs/acs1`: The **path**, which tells the web server how to get to the desired resource.
    - In the case of the Census API, this locates a desired dataset in a particular year.
    - Other APIs allow search functionality. (e.g., News organizations have article searches.) In these cases, the path locates the search function we would like to call.
- `?get=NAME,B02015_009E,B02015_009M&for=state:*`: The **query parameters**, which provide the parameters for the function you would like to call.
    - We can view this as a string of key-value pairs separated by `&`. That is, the general structure of this part is `key1=value1&key2=value2`.

key      value
----     ------
get      NAME,B02015_009E,B02015_009M
for      state:*

Typically, each of these URL components will be specified in the API documentation. Sometimes, the scheme, hostname, and path (`https://api.census.gov/data/2019/acs/acs1`) will be referred to as the **[endpoint](https://en.wikipedia.org/wiki/Web_API#Endpoints)** for the API call.



All right, let's try this!  Let's grab total population and median household income for all census tracts in MN using httr:

```{r}
#| message: FALSE

# Load in your API key
census_api_key <- readLines("~/264_fall_2025/DS2_preview_work/census_api_key.txt")
census_api_key <- readLines("~/SDS264_F25/census_bureau_api_key.txt")
# Alternatively, load your NPS API key using:
# census_api_key <- Sys.getenv("CENSUS_API_KEY")

url <- str_c("https://api.census.gov/data/2020/acs/acs5?get=NAME,B01003_001E,B19013_001E&for=tract:*&in=state:27&in=county:053", "&key=", census_api_key)
acs5 <- GET(url)
details <- content(acs5, "parsed")
# details 
details[[1]]  # variable names
details[[2]]  # list with information on 1st tract

name = character()
population = double()
median_income = double()
tract = character()

for(i in 2:330) {
  name[i-1] <- details[[i]][[1]][1]
  population[i-1] <- details[[i]][[2]][1]
  median_income[i-1] <- details[[i]][[3]][1]
  tract[i-1] <- details[[i]][[6]][1]
}
hennepin_httr <- tibble(
  name = name,
  population = parse_number(population),
  median_income = parse_number(median_income),
  tract = tract
)
hennepin_httr
```

Note: there has been a recently developed [`httr2` package](https://httr2.r-lib.org/), but we will stick with the OG version, which has similar functionality and in some ways is simpler to use. 

### Wrapper packages

In R, it is often easiest to use Web APIs through a **wrapper package**, an R package written specifically for a particular Web API, if one has been written to support a particular website.

- The R development community has already contributed wrapper packages for many large Web APIs (e.g. ZillowR, rtweet, genius, spotifyr, tidycensus, Quandl, nytimes, etc.)
- To find a wrapper package, search the web for "R package" and the name of the website. For example:
    - Searching for "R Reddit package" returns [RedditExtractor](https://github.com/ivan-rivera/RedditExtractor)
    - Searching for "R Weather.com package" returns [weatherData](https://ram-n.github.io/weatherData/)
- [rOpenSci](https://ropensci.org/packages/) also has a good collection of wrapper packages.

Here are two wrapper packages of particular interest to us: 

- `tidycensus`: wrapper package that provides an interface to a few census datasets *with map geometry included!*
    - Full documentation is available at <https://walker-data.com/tidycensus/>

- `censusapi`: wrapper package that offers an interface to all census datasets
    - Full documentation is available at <https://www.hrecht.com/censusapi/>

`get_acs()` is one of the functions that is part of `tidycensus`.  Here we use `get_acs()` to obtain the same variables we acquired above using `httr`:

```{r}
hennepin_tidycensus <- tidycensus::get_acs(
    year = 2021,
    state = "MN",
    geography = "tract",
    variables = c("B01003_001", "B19013_001"),
    output = "wide",
    geometry = TRUE,
    county = "Hennepin",   # specify county in call
    show_call = TRUE       # see resulting query
)
hennepin_tidycensus
```

Obtaining raw data from the Census Bureau was that easy!  Often we will have to obtain and use a secret API key to access the data, but that's not always necessary with `tidycensus`.  (Note: most wrappers DO require an API key!)

Now we can tidy that data and produce plots and analyses.

```{r}
#| warning: FALSE
#| message: FALSE

# Rename cryptic variables from the census form
hennepin_tidycensus <- hennepin_tidycensus |>
  rename(population = B01003_001E,
         population_moe = B01003_001M,
         median_income = B19013_001E,
         median_income_moe = B19013_001M)

# Look for relationships between variables with 1 row per tract

as_tibble(hennepin_tidycensus) |>
  ggplot(aes(x = population, y = median_income)) + 
    geom_point() + 
    geom_smooth(method = "lm")  

# Since census data comes with the geometry of census tracts, we can 
#   plot with geom_sf
ggplot(data = hennepin_tidycensus) + 
  geom_sf(aes(fill = median_income), colour = "white", linetype = 2) + 
  theme_void()  
```



### On Your Own - Census

2. Adapt the code in `hennepin_tidycensus` to write a function called `MN_tract_data` to give the user choices about year, county, and variables to pull off.  Show that `MN_tract_data(year = 2021, county = "Hennepin", variables = c("B01003_001", "B19013_001"))` works as expected.  Make sure it also works for other years, counties, and variables (e.g. B25077_001 is median home price and B02001_002 is number of white residents).
```{r}
MN_tract_data <- function(year, county, variables){
  tidycensus::get_acs(
    year = year,
    state = "MN",
    geography = "tract",
    variables = variables,
    output = "wide",
    geometry = TRUE,
    county = county,   # specify county in call
    show_call = TRUE       # see resulting query
)
}
MN_tract_data(year = 2021, county = "Rice", variables = c("B01003_001", "B02001_002"))
```


3. Use your function from (2) along with `map` and `list_rbind` to build a data set for Rice county for the years 2019-2021.  Use your scraped data to plot trends in income over time and population over time.

```{r}
rice_over_time <- 2019:2021 |>
  map(MN_tract_data,
      county = "Rice",
      variables = c("B01003_001", "B19013_001")) |>
  list_rbind()

rice_over_time <- rice_over_time |>
  mutate(population = "B01003_001E",
         median_income = "B19013_001E") |>
  select(-B01003_001E, -B19013_001E, -B01003_001M, -B01003_001M)

```

